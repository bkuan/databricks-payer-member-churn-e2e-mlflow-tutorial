{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb72bddf-6311-4da6-932f-058240cdf5d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Healthcare Payer Member Churn Prediction\n",
    "## End-to-End MLflow Demo with Databricks Feature Engineering\n",
    "\n",
    "### Overview\n",
    "This notebook demonstrates an end-to-end machine learning workflow for predicting member churn in the healthcare payer industry. Member churn occurs when patients disenroll from a health insurance plan, which can be costly for payers and disruptive to care continuity.\n",
    "\n",
    "**Business Problem**: Healthcare payers need to identify members at risk of disenrollment to implement targeted retention strategies, improve member satisfaction, and reduce acquisition costs.\n",
    "\n",
    "**Solution**: We'll build a predictive model using claims data to identify members likely to disenroll, leveraging:\n",
    "- **Databricks Feature Engineering** for scalable feature management\n",
    "- **MLflow** for experiment tracking and model lifecycle management\n",
    "- **Unity Catalog** for secure model governance\n",
    "- **Champion/Challenger** model comparison strategies\n",
    "\n",
    "### Key Technologies\n",
    "- **Databricks Runtime**: 16.3.x-cpu-ml-scala2.12\n",
    "- **MLflow**: Experiment tracking, model registry, and deployment\n",
    "- **Feature Engineering Client**: Feature store management\n",
    "- **Unity Catalog**: Centralized governance\n",
    "\n",
    "### Prerequisites\n",
    "⚠️ **Note**: Ensure that classic compute assigned to single user or group is used with Databricks runtime **16.3.x-cpu-ml-scala2.12** or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec1842a1-ae1b-4503-9746-05f9ecd67141",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# 1. Data Preparation and Loading\n",
    "\n",
    "In this section, we'll load healthcare claims data that will be used to predict member disenrollment. The data contains detailed claims information including:\n",
    "- **Member demographics**: age, date of birth\n",
    "- **Claims activity**: service dates, claim types, amounts\n",
    "- **Provider information**: provider IDs, service locations\n",
    "- **Claim status**: approved, denied, paid amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "87e062c0-1a44-4d90-b5eb-2cc88c59935b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Load raw claims data from Databricks Volumes\n",
    "-- Data is ingested by dropping CSV files into a volume, which automatically populates the claims table\n",
    "-- This pattern enables easy data ingestion from various payers\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS demo.hls.PAYER_DETAILED_CLAIMS\n",
    "FROM\n",
    "  READ_FILES('/Volumes/demo/hls/payer_detailed_claims/*.csv', format => 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1ded44e8-4ff4-4aca-ba27-245854246c13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "%pip install databricks-feature-engineering\n",
    "\n",
    "# Restart Python to load the newly installed packages\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71fc4f17-953d-499a-9a54-0430a97f4b28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    brier_score_loss\n",
    ")\n",
    "import mlflow\n",
    "\n",
    "# Load claims data from Delta table\n",
    "df = spark.table(\"demo.hls.PAYER_DETAILED_CLAIMS\")\n",
    "\n",
    "print(f\"Total records loaded: {df.count():,}\")\n",
    "print(f\"Total unique members: {df.select('member_id').distinct().count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "466c64b2-74da-4e40-a923-b9c159e13f84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# 2. Feature Engineering\n",
    "\n",
    "Feature engineering is critical for predicting member churn. We'll create features that capture:\n",
    "\n",
    "**Temporal Patterns**:\n",
    "- Days between consecutive claims (engagement frequency)\n",
    "- Days since last claim (recency indicator)\n",
    "- Number of months with claims (tenure activity)\n",
    "\n",
    "**Utilization Metrics**:\n",
    "- Total number of claims\n",
    "- Claim type distribution (Inpatient, Outpatient, Pharmacy, Professional)\n",
    "- Number of distinct providers used\n",
    "\n",
    "**Financial Indicators**:\n",
    "- Total and average charge amounts\n",
    "- Total and average paid amounts\n",
    "- Denial rate (percentage of denied claims)\n",
    "- Allowed-to-paid ratio\n",
    "\n",
    "**Member Demographics**:\n",
    "- Age calculated from date of birth\n",
    "\n",
    "These features help identify patterns that distinguish members who are likely to disenroll from those who remain active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2072a527-4bb2-4505-a564-146f4b22b9a1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create a Label and Feature Table to avoid label leakage"
    }
   },
   "outputs": [],
   "source": [
    "## 2.1 Date Preprocessing\n",
    "# Convert string dates to proper date types\n",
    "cols_to_cast = [\"service_date\", \"dob\"]\n",
    "for col_name in cols_to_cast:\n",
    "    df = df.withColumn(col_name, to_date(col_name))\n",
    "\n",
    "## 2.2 Temporal Features - Calculate days between consecutive claims\n",
    "# Use window functions to calculate claim frequency patterns\n",
    "w = Window.partitionBy(\"member_id\").orderBy(\"service_date\")\n",
    "df_with_lag = df.withColumn(\"prev_date\", lag(\"service_date\").over(w)) \\\n",
    "                .withColumn(\"gap_days\", datediff(col(\"service_date\"), col(\"prev_date\")))\n",
    "\n",
    "## 2.3 Claim Type Distribution - Pivot claim types for each member\n",
    "claim_type_pivot = df.groupBy(\"member_id\").pivot(\"claim_type\").count().na.fill(0)\n",
    "\n",
    "## 2.4 Aggregate Features at Member Level\n",
    "features_df = df.groupBy(\"member_id\").agg(\n",
    "    # Utilization metrics\n",
    "    count(\"*\").alias(\"num_claims_total\"),\n",
    "    countDistinct(\"provider_id\").alias(\"num_distinct_providers\"),\n",
    "    countDistinct(col(\"service_date\").substr(0,7)).alias(\"num_months_with_claims\"),\n",
    "    \n",
    "    # Quality/Status metrics\n",
    "    (sum(when(col(\"status\") == \"Denied\", 1).otherwise(0)) / count(\"*\")).alias(\"pct_denied_claims\"),\n",
    "    \n",
    "    # Financial metrics\n",
    "    sum(\"charge_amount\").alias(\"total_charge_amount\"),\n",
    "    sum(\"paid_amount\").alias(\"total_paid_amount\"),\n",
    "    avg(\"allowed_amount\").alias(\"avg_allowed_amount\"),\n",
    "    avg(\"paid_amount\").alias(\"avg_paid_amount\"),\n",
    "    \n",
    "    # Temporal markers\n",
    "    max(\"service_date\").alias(\"last_claim_date\"),\n",
    "    min(\"service_date\").alias(\"first_claim_date\"),\n",
    "    \n",
    "    # Demographics\n",
    "    max(months_between(current_date(), col(\"dob\")) / 12).alias(\"age\")\n",
    ")\n",
    "\n",
    "## 2.5 Add temporal gap features\n",
    "avg_gap = df_with_lag.groupBy(\"member_id\").agg(avg(\"gap_days\").alias(\"avg_days_between_claims\"))\n",
    "\n",
    "## 2.6 Combine all features\n",
    "features_df = features_df.join(avg_gap, on=\"member_id\", how=\"left\")\n",
    "features_df = features_df.join(claim_type_pivot, on=\"member_id\", how=\"left\")\n",
    "\n",
    "# Calculate derived ratio\n",
    "features_df = features_df.withColumn(\"avg_allowed_paid_ratio\", col(\"avg_allowed_amount\") / col(\"avg_paid_amount\"))\n",
    "\n",
    "# Add recency metric\n",
    "features_df = features_df.withColumn(\"days_since_last_claim\", datediff(current_date(), col(\"last_claim_date\")))\n",
    "\n",
    "# Add versioning timestamp for feature store\n",
    "features_df = features_df.withColumn(\"version_ts\", current_timestamp())\n",
    "\n",
    "## 2.7 Create Target Variable (Label)\n",
    "# Define disenrollment: members with no claims in the last 180 days are considered disenrolled\n",
    "label_features_df = features_df.withColumn(\n",
    "    \"disenrolled\", \n",
    "    when(col(\"days_since_last_claim\") > 180, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Remove date columns that won't be used in modeling\n",
    "label_features_df = label_features_df.drop(\"last_claim_date\", \"first_claim_date\", \"days_since_last_claim\")\n",
    "\n",
    "print(f\"Features created for {label_features_df.count():,} members\")\n",
    "print(f\"Disenrollment rate: {label_features_df.filter(col('disenrolled') == 1).count() / label_features_df.count():.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93eb0fe3-0c7b-4999-b6c5-b11dcc54b49a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "# 3. Feature Store Management with Databricks\n",
    "\n",
    "The **Databricks Feature Engineering** client provides a centralized feature store that:\n",
    "- **Tracks feature lineage**: Automatically links features to models\n",
    "- **Enables feature reuse**: Share features across multiple models and teams\n",
    "- **Supports point-in-time lookups**: Ensures training/serving consistency\n",
    "- **Manages versioning**: Track feature evolution over time\n",
    "\n",
    "We'll create two tables:\n",
    "1. **Label table**: Contains labels (disenrolled) along with features for model training\n",
    "2. **Feature table**: Contains only features for inference and feature sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29b24909-acb6-4c0e-9937-1625bba11397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Clean up existing table if needed (for demo purposes)\n",
    "DROP TABLE IF EXISTS demo.hls.label_features_versioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0898dd2d-d0ad-4111-92b7-90cd85037ed0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Label Table for Training"
    }
   },
   "outputs": [],
   "source": [
    "# Save label + features table as a Delta table\n",
    "# This table contains both features and the target variable for training\n",
    "label_features_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"demo.hls.label_features_versioned\")\n",
    "\n",
    "print(\"✓ Label features table saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb0f350e-9f74-4b8b-9685-8c7f743ad1f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Define primary key constraints for the label features table\n",
    "-- This ensures data quality and enables proper feature store functionality\n",
    "\n",
    "ALTER TABLE demo.hls.label_features_versioned DROP CONSTRAINT IF EXISTS member_labels_versioned_pk;\n",
    "ALTER TABLE demo.hls.label_features_versioned ALTER COLUMN member_id SET NOT NULL;\n",
    "ALTER TABLE demo.hls.label_features_versioned ALTER COLUMN version_ts SET NOT NULL;\n",
    "ALTER TABLE demo.hls.label_features_versioned ADD CONSTRAINT member_labels_versioned_pk PRIMARY KEY(member_id, version_ts);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a59016e-bfd5-41f7-8d71-331b8e8fa144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Viewing Feature Tables\n",
    "\n",
    "Feature store tables are saved as Delta tables in Unity Catalog. You can:\n",
    "- Browse them in **Catalog Explorer** (left sidebar → Catalog)\n",
    "- Query them using SQL\n",
    "- Track their lineage and usage\n",
    "- Set permissions and governance policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f18f744-5379-4181-8174-e17be2c6961f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755127141838}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preview the label features table\n",
    "display(label_features_df.limit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d02f5d6-fc84-43fa-8214-86d542b8eff2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 3.1 Register Features with Feature Engineering Client\n",
    "\n",
    "Now we'll register the feature table with the Feature Engineering client. This provides:\n",
    "- **Automatic lineage tracking**: Link features to models automatically\n",
    "- **Point-in-time correctness**: Use `timeseries_columns` to ensure temporal consistency\n",
    "- **Feature discovery**: Teams can browse and reuse features\n",
    "- **Serving integration**: Features can be automatically looked up during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89bb5f35-5cba-4833-8eb7-f22fc48a204c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create \"feature\" / UC Table with the Feature Engineering Client"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Feature Engineering Client\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# Create feature table in Unity Catalog\n",
    "# This registers the table with the feature store for lineage tracking\n",
    "disenrollment_feature_table = fe.create_table(\n",
    "    name=\"demo.hls.member_features_versioned\",\n",
    "    primary_keys=[\"member_id\", \"version_ts\"],\n",
    "    schema=features_df.schema,\n",
    "    timeseries_columns=\"version_ts\",  # Enables point-in-time lookups\n",
    "    description=\"Member churn prediction features derived from claims data for PAYER1\"\n",
    ")\n",
    "\n",
    "print(\"✓ Feature table registered in Unity Catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c44fbe2-f202-4966-8d6c-ed25986c2841",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write features to table"
    }
   },
   "outputs": [],
   "source": [
    "# Write features to the feature store\n",
    "# 'merge' mode supports schema evolution and incremental updates\n",
    "fe.write_table(\n",
    "    name=\"demo.hls.member_features_versioned\",\n",
    "    df=features_df,  # Can also be a streaming DataFrame for real-time updates\n",
    "    mode='merge'  # Supports schema evolution and upserts\n",
    ")\n",
    "\n",
    "print(\"✓ Features written to feature store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2d30a04-aed0-4c69-98c0-6cd4c04eb952",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755127181029}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify features were written correctly (showing most recent versions)\n",
    "SELECT * FROM demo.hls.member_features_versioned \n",
    "ORDER BY version_ts DESC \n",
    "LIMIT 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8125ac82-32e9-415a-892b-c0e6ad33cefd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 3.2 On-Demand Feature Functions (Optional)\n",
    "\n",
    "**Feature Functions** allow you to define features that are calculated on-demand at inference time, rather than pre-computed and stored. This is useful for:\n",
    "- **Time-dependent features**: Like age, which changes over time\n",
    "- **Complex transformations**: That depend on multiple inputs\n",
    "- **Dynamic calculations**: That need to be computed at serving time\n",
    "\n",
    "Example: Member age needs to be calculated based on the current date at inference time, not pre-computed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a5f4391-ec02-495d-afaf-339253769694",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define a udf for calculating current age"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create a user-defined function to calculate age dynamically at inference time\n",
    "-- This ensures age is always current, not stale from training time\n",
    "\n",
    "CREATE OR REPLACE FUNCTION demo.hls.current_age(dob DATE)\n",
    "RETURNS INT\n",
    "LANGUAGE PYTHON\n",
    "COMMENT \"[Feature Function] Calculate current age based on date of birth\"\n",
    "AS $$\n",
    "from datetime import datetime\n",
    "if dob is None:\n",
    "    return None\n",
    "    \n",
    "current_date = datetime.now()\n",
    "age = current_date.year - dob.year - ((current_date.month, current_date.day) < (dob.month, dob.day))\n",
    "return age\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a37c1df-bb5f-47db-a856-d1eb671aa25d",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755016373654}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify the function was created successfully\n",
    "DESCRIBE FUNCTION demo.hls.current_age;\n",
    "\n",
    "-- Test the function (uncomment to test):\n",
    "-- SELECT demo.hls.current_age('1989-09-14') as calculated_age;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_41a50460-c90b-4840-9288-afcb847395d5",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8994656465154948,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Healthcare Payer Member Churn - Model Development",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
